# General parameters
dataset: News
model_name: TabTransformer_our # LinearModel, KNN, SVM, DecisionTree, RandomForest, XGBoost, CatBoost, LightGBM, ModelTree
                # MLP, TabNet, VIME, TabTransformer, RLN, DNFNet, STG, NAM, DeepFM, SAINT
objective: binary # Don't change
missingrate: 0.5
optimize_hyperparameters: False
type: mcar
imp_name: mean
# GPU parameters
use_gpu: True
gpu_ids: [0]
data_parallel: True

# Optuna parameters - https://optuna.org/
n_trials: 2
direction: maximize

# Cross validation parameters
num_splits: 5
shuffle: True
seed: 0 # Don't change

# Preprocessing parameters
scale: True
target_encode: True
one_hot_encode: False

# Training parameters
batch_size: 128
val_batch_size: 256
early_stopping_rounds: 5
epochs: 1000
logging_period: 100

# About the data
num_classes: 1  # for classification
num_features: 14
cat_idx: [1,3,5,6,7,8,9,13]
# cat_dims: will be automatically set.
cat_dims: [9, 16, 7, 15, 6, 5, 2, 42]